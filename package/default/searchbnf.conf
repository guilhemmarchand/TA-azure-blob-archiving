# searchbnf.conf

[azexporttable-command]
syntax = | azexporttable table_target=<target Az table> field_storage_account=<StorageAccount> field_table=<Table> field_partitionkey=<PartitionKey> field_row_key=<RowKey> field_blob_name=<blob_name> field_bucket_id=<bucket_id> field_original_bucket_name=<original_bucket_name> field_original_peer_name=<original_peer_name> field_original_peer_guid=<original_peer_guid> field_epoch_start=<epoch_start> field_epoch_end=<epoch_start> field_indexname=<indexname> field_size_bytes=<size_bytes> field_clustered_flag=<clustered_flag>
description = \
    This command is streaming command to export Splunk results to an Azure Storage table for migration purposes. \
    Syntax: \
    | azexporttable table_target=<target Az table> field_storage_account=<StorageAccount> field_table=<Table> field_partitionkey=<PartitionKey> field_row_key=<RowKey> field_blob_name=<blob_name> field_bucket_id=<bucket_id> field_original_bucket_name=<original_bucket_name> field_original_peer_name=<original_peer_name> field_original_peer_guid=<original_peer_guid> field_epoch_start=<epoch_start> field_epoch_end=<epoch_start> field_indexname=<indexname> field_size_bytes=<size_bytes> field_clustered_flag=<clustered_flag>
comment1 = \
    This example shows how to export downstream results to an Azure table.
example1 = \
    | azexporttable table_target="testexport" field_storage_account="StorageAccount" field_table="Table" field_partitionkey="PartitionKey" field_row_key="RowKey" field_blob_name="blob_name" field_bucket_id="bucket_id" field_original_bucket_name="original_bucket_name" field_original_peer_name="original_peer_name" field_original_peer_guid="original_peer_guid" field_epoch_start="epoch_start" field_epoch_end="epoch_start" field_indexname="indexname" field_size_bytes="size_bytes" field_clustered_flag="clustered_flag"
shortdesc = Export Splunk downstream results to an Azure Storage table.
usage = public
tags = TA-azure-blob-archiving

[azpurgeblob-command]
syntax = | azepurgeblob mode=<run time mode, simulate or live> update_table=<attempt to update the Az table, true or false> field_blob_name=<blob_name> field_storage_account=<StorageAccount> field_table=<Table> field_partitionkey=<PartitionKey> field_row_key=<RowKey>
description = \
    This command is streaming command that allows purging blobs from the upstream Splunk search results. \
    Syntax: \
    | azexporttable mode=<run time mode, simulate or live> update_table=<attempt to update the Az table, true or false> field_blob_name=<blob_name> field_storage_account=<StorageAccount> field_table=<Table> field_partitionkey=<PartitionKey> field_row_key=<RowKey>
comment1 = \
    This example shows how to purge blobs from an upstream Splunk search. 
example1 = \
    | azpurgeblob mode="live" update_table="true" field_storage_account="StorageAccount" field_blob_name="blob_name" field_table="Table" field_partitionkey="PartitionKey" field_row_key="RowKey"
shortdesc = Purge blobs in Azure
usage = public
tags = TA-azure-blob-archiving

[azgettable-command]
syntax = | azgettable target_table=<name of the target Storage table> partition_key=<value of the PartitionKey> custom_filter=<custom filter to be added>
description = \
    This custom command is a generating command that retrieves the entire content of the storage table. \
    Syntax: \
    | azgettable target_table=<name of the target Storage table> partition_key=<value of the PartitionKey> custom_filter=<custom filter to be added>
comment1 = \
    This example shows how to get the live content from the Azure Storage table
example1 = \
    | azgettable target_table="splunkdb" partition_key="splunk-archives" custom_filter="status eq 'deleted'" | spath
shortdesc = Retrieve the Azure Storage Table content
usage = public
tags = TA-azure-blob-archiving

[azure2blob-command]
syntax = | azure2blob url=<API endpoint> mode=<HTTP method: get/post/delete> body=<Optional: provides the HTTP body in a json format>
description = \
    This command is a REST API wrapper for the app API endpoints, it allows performing \
    get / post / delete HTTP calls against an endpoint and returns a JSON format answer. \
    Syntax: \
    | azure2blob url=<API endpoint> mode=<HTTP method: get/post/delete> body=<Optional: provides the HTTP body in a json format>
comment1 = \
    This example calls the smart_status endpoint to provide an advanced status with automated \
    correlations and investigations.
example1 = \
    | azure2blob url=/services/ta_azure_blob_archiving/v1/restore mode=post body="{'splunk_rebuild': 'True', 'blob_name': 'firewall/2022/01/firewall_AFCCD78D-EBDD-4353-B9F3-D892DBE8778C_2.tgz', 'target_directory': '/opt/splunk/var/lib/splunk/firewall/thaweddb'}"
shortdesc = REST API wrapper for Azure2Blob, allows performing \
    get / post / delete HTTP calls against an endpoint.
usage = public
tags = TA-azure-blob-archiving

[azrestorebatch-command]
syntax = | azrestorebatch field_blob_name=<field name containing the blob_name> field_target_directory=<field name containing the target directory> field_target_peer=<field name containing the target peer> splunk_rebuild=<perform Splunk rebuild>
description = \
    This command is streaming command to batch restore any number of buckets, either to a local or remote instances. \
    Syntax: \
    | azrestorebatch field_blob_name=<field name containing the blob_name> field_target_directory=<field name containing the target directory> field_target_peer=<field name containing the target peer> splunk_rebuild=<perform Splunk rebuild>
comment1 = \
    This example shows how to mass restore buckets.
example1 = \
    | azrestorebatch field_blob_name="blob_name" field_target_directory="target_directory" field_target_peer="original_peer_name" splunk_rebuild="True"
shortdesc = Perform mass restore buckets operations.
usage = public
tags = TA-azure-blob-archiving
